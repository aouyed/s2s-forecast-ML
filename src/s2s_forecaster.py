#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Wed Nov 30 17:55:33 2022@author: aouyed"""import xarray as xrimport pandas as pdimport numpy as npfrom sklearn.ensemble import RandomForestRegressorfrom sklearn.linear_model import LinearRegressionfrom scipy.stats import kurtosis, skewfrom sklearn.impute import SimpleImputerSEASONS=['DJF','MAM','JJA','SON']VARX=['P_anom','T_anom']VARY=['P_anom','T_anom']TRAIN_SIZE=0.7ROLL_DT=4class s2s_forecaster:    def __init__(self,lead=2, varx=VARX, vary=VARY, tr_size=TRAIN_SIZE, roll_dt=ROLL_DT, seas='all'):        reg1=LinearRegression()        reg2=RandomForestRegressor()        #reg2=RandomForestRegressor()        self.VARS=['P','T','SWE']        self.lead=lead        self.rolling_dt=roll_dt        self.varis_x=varx        self.varis_y=vary        self.train_size=tr_size        self.season=seas        self.ds_prism, self.ds_gefs=self.preprocess_ds(self.lead)        self.ds_pred_linear=self.regression(reg1)        self.ds_pred_rf=self.regression(reg2)        self.ds_pred_stacked=self.stacked_regressor(reg1,reg2)               self.ds_rmse_linear, self.ds_error_linear=self.error_calculator(self.ds_pred_linear.copy(), self.ds_prism.copy())        self.ds_rmse_rf, self.ds_error_rf=self.error_calculator(self.ds_pred_rf.copy(), self.ds_prism.copy())        self.ds_rmse_gefs, self.ds_error_gefs=self.error_calculator(self.ds_gefs.copy(), self.ds_prism.copy())        #self.ds_rmse_stacked, self.ds_error_stacked=self.error_calculator(self.ds_pred_stacked.copy(), self.ds_prism.copy())                def stacked_regressor(self, regressor1, regressor2):        _, ds_total,x_total =self.ml_calculator(self.ds_prism.copy(), self.ds_gefs.copy(), regressor1, self.varis_x, self.varis_y)        ds_total=self.teleconnect_total(ds_total)        new_varis=self.varis_x.copy()        new_varis.append('month')        new_varis.append('NINO3.4')        new_varis.append('NAO')                if 'P_anom' not in self.varis_x:            ds_total['P_anom']=x_total['P_anom']        if 'T_anom' not in self.varis_x:            ds_total['T_anom']=x_total['T_anom']                    ds_pred, _, _ =self.ml_calculator(self.ds_prism.copy(), ds_total.copy(), regressor2, new_varis,  self.varis_y)        return ds_pred            def regression(self, regressor):        ds_pred, _,_ =self.ml_calculator(self.ds_prism.copy(), self.ds_gefs.copy(), regressor, self.varis_x, self.varis_y)        return ds_pred            def error_calculator(self,ds_pred, ds_prism):        if self.season in SEASONS:            ds_pred= ds_pred.sel(time=ds_pred.time.dt.season==self.season)            ds_prism= ds_prism.sel(time=ds_prism.time.dt.season==self.season)        ds_error=(ds_prism-ds_pred)**2        ds_error=self.clim_error(ds_error, ds_prism)        squared_error_mean=ds_error.groupby('basin').mean('time')        ds_rmse=np.sqrt(squared_error_mean)        ds_error=abs(ds_prism-ds_pred)        ds_error=self.clim_error(ds_error, ds_prism)        return ds_rmse, ds_error         def clim_error(self, ds_error, ds_prism):        for var in self.VARS:            ds_error[var+'_clim']=(ds_prism[var+'_climatology']-ds_prism[var])**2        return ds_error        def preprocess_ds(self, lead):        ds=xr.open_dataset('../data/raw/GEFS_and_Observations_of_P_T_SWE_SM.nc')        #df=ds.to_dataframe().reset_index()                ds['basin']=ds['basin']+1        ds_prism=ds[['PRISM_P','PRISM_T','UA_SWE']]        ds_prism=ds_prism.rename({'PRISM_P':'P','PRISM_T': 'T','UA_SWE':'SWE'})        ds_gefs=ds[['GEFS_P','GEFS_T','GEFS_SWE']]        ds_gefs=ds_gefs.rename({'GEFS_P':'P','GEFS_T': 'T','GEFS_SWE':'SWE'})        ds_gefs=ds_gefs.loc[{'lead':lead}].copy()        ds_gefs['P_std']=ds_gefs['P'].std(dim='ensemble')        ds_gefs['T_std']=ds_gefs['T'].std(dim='ensemble')        ds_gefs['SWE_std']=ds_gefs['SWE'].std(dim='ensemble')                                                            ds_gefs['P']=ds_gefs['P'].mean(dim='ensemble')        ds_gefs['T']=ds_gefs['T'].mean(dim='ensemble')        ds_gefs['SWE']=ds_gefs['SWE'].std(dim='ensemble')                ds_gefs=ds_gefs.drop('ensemble')        ds_prism,ds_gefs=self.climatology(ds_prism, ds_gefs, lead)        ds_prism=self.teleconnect_total(ds_prism)        ds_gefs=self.teleconnect_total(ds_gefs)        return ds_prism, ds_gefs        def climatology(self, ds_prism, ds_gefs, lead):        climatology_mean = ds_prism.groupby("time.week").mean("time")        anomalies = ds_prism.groupby("time.week") - climatology_mean        ds_prism_base=ds_prism.copy()        ds_gefs_base=ds_gefs.copy()        for var in ds_prism_base:             ds_prism_base[var+'_anom']=ds_prism[var].groupby("time.week")-climatology_mean[var]            ds_prism_base[var+'_climatology']=-ds_prism_base[var+'_anom']+ds_prism_base[var]            ds_gefs_base[var+'_anom']=ds_gefs_base[var].groupby("time.week")-climatology_mean[var]            #ds_gefs_base[var+'_climatology']=-ds_prism_base[var+'_anom']+ds_prism_base[var]        return ds_prism_base, ds_gefs_base        def ds_split(self, ds_prism, ds_gefs):        size_index=self.train_size*ds_prism['time'].values.shape[0]        size_index=int(size_index)        times_train=ds_prism['time'].values[:size_index]        times_test=ds_prism['time'].values[size_index:]                ds_prism_train=ds_prism.sel(time=times_train)        ds_gefs_train=ds_gefs.sel(time=times_train)        ds_prism_test=ds_prism.sel(time=times_test)        ds_gefs_test=ds_gefs.sel(time=times_test)        return ds_prism_train, ds_gefs_train, ds_prism_test,  ds_gefs_test        def df_processor(self, ds_x, ds_y, basin):        clim=ds_y[['T','P','SWE','T_climatology','P_climatology','SWE_climatology','time']].to_dataframe().reset_index()            df_x=ds_x.to_dataframe().reset_index()        df_y=ds_y.to_dataframe().reset_index()                df_x.loc[:,'month']=pd.DatetimeIndex(df_x.reset_index()['time']).month        df_x.loc[:,'year']=pd.DatetimeIndex(df_x.reset_index()['time']).year        df_x.loc[:,'week']=pd.DatetimeIndex(df_x.reset_index()['time']).week         imputer = SimpleImputer()        df_x[['P_anom','T_anom']]=imputer.fit_transform(df_x[['P_anom','T_anom']])        df_y[['P_anom','T_anom']]=imputer.fit_transform(df_y[['P_anom','T_anom']])         return df_x, df_y, clim            def teleconnect_ds(self,ds, file):                df=ds.to_dataframe()                df.loc[:,'month']=pd.DatetimeIndex(df.reset_index()['time']).month        df.loc[:,'year']=pd.DatetimeIndex(df.reset_index()['time']).year        df=df.reset_index()                df_i=pd.read_csv(file, sep='   ', engine='python')        df_i['month']=df_i['month']+1        df_i.loc[df_i.month==13,'month']=1        df= pd.merge(df,df_i,how='left',on=['month','year'])        df=df.reset_index().set_index(['time','basin']).drop('index',axis=1)        ds=xr.Dataset.from_dataframe(df)        return ds        def teleconnect_total(self,ds):        file='../data/raw/ersst5.nino.mth.81-10.ascii'        ds=self.teleconnect_ds(ds, file)        file='../data/raw/norm.nao.monthly.b5001.current.ascii.txt'        ds=self.teleconnect_ds(ds, file)        ds=ds.rename({'anom':'NAO'})        return ds    def ds_correlate(self, ds,var1='P_anom',var2='NINO3.4', season='DJF'):        if season in SEASONS:            ds= ds.sel(time=ds.time.dt.season==season)            df=ds.to_dataframe().reset_index()        return xr.corr(ds[var1], ds[var2], dim="time")        def ml_function(self, x_train,y_train,x_test, clim, varx,vary, regressor, basin):        x_train= x_train[varx]        y_train= y_train[vary]        x_test=x_test[varx]        if x_train.ndim>1:            regressor.fit(x_train, y_train)        else:            x_train=x_train.values            regressor.fit(x_train.reshape(1,-1), y_train)              y_pred = regressor.predict(x_test)        y_pred=pd.DataFrame(y_pred, columns=vary)        y_pred=pd.concat([y_pred,clim], axis=1)        y_pred['basin']=basin                return y_pred          def ml_calculator(self, ds_prism, ds_gefs, regressor, varx, vary):        if self.rolling_dt>0:            ds_prism[['P_anom','T_anom']]=ds_prism[['P_anom','T_anom']].rolling(time=self.rolling_dt).mean()            ds_gefs[['P_anom','T_anom']]=ds_gefs[['P_anom','T_anom']].rolling(time=self.rolling_dt).mean()                if self.season in SEASONS:            ds_prism= ds_prism.sel(time=ds_prism.time.dt.season==self.season)            ds_gefs= ds_gefs.sel(time=ds_gefs.time.dt.season==self.season)        ds_prism_train, ds_gefs_train, ds_prism_test,  ds_gefs_test=self.ds_split(ds_prism, ds_gefs)                y_pred_total=pd.DataFrame()        y_pred_test_total=pd.DataFrame()        x_total=pd.DataFrame()        #regressor=LinearRegression()        for basin in ds_prism['basin'].values:            ds_x=ds_gefs.sel(basin=basin)            ds_y=ds_prism.sel(basin=basin)            ds_x_train=ds_gefs_train.sel(basin=basin)            ds_y_train=ds_prism_train.sel(basin=basin)            ds_x_test=ds_gefs_test.sel(basin=basin)            ds_y_test=ds_prism_test.sel(basin=basin)                        x_test, y_test, clim_test=self.df_processor(ds_x_test, ds_y_test, basin)            x_train, y_train,clim_train=self.df_processor(ds_x_train, ds_y_train, basin)            x, y,clim=self.df_processor(ds_x, ds_y, basin)            y_pred= self.ml_function(x,y,x, clim, varx,vary, regressor,basin)            y_pred_test= self.ml_function(x_train,y_train,x_test, clim_test, varx,vary, regressor,basin)            if y_pred_total.empty:                y_pred_total=y_pred                y_pred_test_total=y_pred_test                x_total=x            else:                y_pred_total=pd.concat([y_pred_total,y_pred])                y_pred_test_total=pd.concat([y_pred_test_total,y_pred_test])                x_total=pd.concat([x_total,x])                    y_pred_total=y_pred_total.set_index(['basin','time'])          y_pred_test_total=y_pred_test_total.set_index(['basin','time'])                x_total=x_total.set_index(['basin','time'])                ds_pred=xr.Dataset.from_dataframe(y_pred_total)        ds_pred_test=xr.Dataset.from_dataframe(y_pred_test_total)        ds_x_total=xr.Dataset.from_dataframe(x_total)        return ds_pred_test, ds_pred, ds_x_total